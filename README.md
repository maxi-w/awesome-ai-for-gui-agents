# Awesome AI for the Graphical User Interface Domain

This list features awesome projects, models and datasets around AI on graphical user interfaces.

## Models

### Fuyu-8B
https://www.adept.ai/blog/fuyu-8b

https://huggingface.co/adept/fuyu-8b

### Pix2Struct
https://github.com/google-research/pix2struct

https://huggingface.co/google/pix2struct-base

## Datasets

### Rico: A Mobile App Dataset for Building Data-Driven Design Applications
http://www.interactionmining.org/rico.html

### UI understanding datasets for UIBert
https://github.com/google-research-datasets/uibert

Two datasets that are extended from the public Rico dataset, which contains 72k mobile app UI data. They add two different types of annotations to these UIs.


1. In AppSim, each datapoint contains two UIs of similar category and the annotation of two semantically similar UI elements on them, such as a “Menu” buttons that appear on two UIs.
2. In RefExp, each datapoint contains a UI and a referring expression of a UI element on it, such as “Red button on the top”.

## Research Papers

[UIBert: Learning Generic Multimodal Representations for UI Understanding](https://arxiv.org/abs/2107.13731) (07/2021)

[Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding](https://arxiv.org/abs/2210.03347) (06/2023)

[Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs](https://arxiv.org/abs/2404.05719) (04/2024)

[VUT: Versatile UI Transformer for Multi-Modal Multi-Task User Interface Modeling](https://arxiv.org/abs/2112.05692) (12/2021)

[META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI](https://arxiv.org/abs/2205.11029) (05/2022)


## Blogs
